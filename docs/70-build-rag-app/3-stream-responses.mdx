# ü¶π Stream responses from the RAG application

By default, generation results are return once the generation is completed. Another option is to stream the results, which is useful for chat use cases where the user can incrementally see results as each token is generated.

Fill in any `<CODE_BLOCK_N>` placeholders and run the cells under the **ü¶π‚Äç‚ôÄÔ∏è Return streaming responses** section in the notebook to stream the results from your RAG application.

The answers for code blocks in this section are as follows:

**CODE_BLOCK_23**

<details>
<summary>Answer</summary>
<div>
```python
fw_client.chat.completions.create(
    model=model,
    temperature=0,
    stream=True,
    messages=[
        {
            "role": "user",
            "content": create_prompt(user_query),
        }
    ],
)
```
</div>
</details>

**CODE_BLOCK_24**

<details>
<summary>Answer</summary>
<div>
```python
for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```
</div>
</details>