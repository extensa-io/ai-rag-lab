"use strict";(self.webpackChunkai_rag_lab=self.webpackChunkai_rag_lab||[]).push([[951],{3943:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Introduction","href":"/ai-rag-lab/docs/intro","docId":"intro","unlisted":false},{"type":"category","label":"Retrieval Augmented Generation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udcd8 What is RAG?","href":"/ai-rag-lab/docs/rag/what-is-rag","docId":"rag/what-is-rag","unlisted":false},{"type":"link","label":"\ud83d\udcd8 When to use RAG?","href":"/ai-rag-lab/docs/rag/rag-usecases","docId":"rag/rag-usecases","unlisted":false},{"type":"link","label":"\ud83d\udcd8 Components of a RAG system","href":"/ai-rag-lab/docs/rag/components-of-rag","docId":"rag/components-of-rag","unlisted":false}],"href":"/ai-rag-lab/docs/category/retrieval-augmented-generation"},{"type":"category","label":"MongoDB Atlas","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udc50 MongoDB Setup","href":"/ai-rag-lab/docs/mongodb-atlas/setup","docId":"mongodb-atlas/setup","unlisted":false}],"href":"/ai-rag-lab/docs/category/mongodb-atlas"},{"type":"category","label":"Dev Environment","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udcd8 Running Jupyter Notebooks","href":"/ai-rag-lab/docs/dev-env/jupyter-notebooks","docId":"dev-env/jupyter-notebooks","unlisted":false},{"type":"link","label":"\ud83d\udc50 Setup dev environment","href":"/ai-rag-lab/docs/dev-env/dev-setup","docId":"dev-env/dev-setup","unlisted":false},{"type":"link","label":"\ud83d\udc50 Setup prerequisites","href":"/ai-rag-lab/docs/dev-env/setup-pre-reqs","docId":"dev-env/setup-pre-reqs","unlisted":false}],"href":"/ai-rag-lab/docs/category/dev-environment"},{"type":"category","label":"Prepare the Data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udc50 Load the dataset","href":"/ai-rag-lab/docs/prepare-the-data/load-data","docId":"prepare-the-data/load-data","unlisted":false},{"type":"link","label":"\ud83d\udc50 Chunk up the data","href":"/ai-rag-lab/docs/prepare-the-data/chunk-data","docId":"prepare-the-data/chunk-data","unlisted":false},{"type":"link","label":"\ud83d\udc50 Generate embeddings","href":"/ai-rag-lab/docs/prepare-the-data/embed-data","docId":"prepare-the-data/embed-data","unlisted":false},{"type":"link","label":"\ud83d\udc50 Ingest data into MongoDB","href":"/ai-rag-lab/docs/prepare-the-data/ingest-data","docId":"prepare-the-data/ingest-data","unlisted":false}],"href":"/ai-rag-lab/docs/category/prepare-the-data"},{"type":"category","label":"Perform Semantic Search on Your Data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udcd8 Semantic search in MongoDB","href":"/ai-rag-lab/docs/perform-semantic-search/concepts","docId":"perform-semantic-search/concepts","unlisted":false},{"type":"link","label":"\ud83d\udc50 Create a vector search index","href":"/ai-rag-lab/docs/perform-semantic-search/create-vector-index","docId":"perform-semantic-search/create-vector-index","unlisted":false},{"type":"link","label":"\ud83d\udc50 Perform semantic search","href":"/ai-rag-lab/docs/perform-semantic-search/vector-search","docId":"perform-semantic-search/vector-search","unlisted":false},{"type":"link","label":"\ud83e\uddb9 Combine pre-filtering with vector search","href":"/ai-rag-lab/docs/perform-semantic-search/pre-filtering","docId":"perform-semantic-search/pre-filtering","unlisted":false}],"href":"/ai-rag-lab/docs/category/perform-semantic-search-on-your-data"},{"type":"category","label":"Build the RAG Application","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udc50 Build the RAG application","href":"/ai-rag-lab/docs/build-rag-app/build-rag-app","docId":"build-rag-app/build-rag-app","unlisted":false},{"type":"link","label":"\ud83e\uddb9 Re-rank retrieved results","href":"/ai-rag-lab/docs/build-rag-app/add-reranking","docId":"build-rag-app/add-reranking","unlisted":false}],"href":"/ai-rag-lab/docs/category/build-the-rag-application"},{"type":"category","label":"Add memory to the RAG application","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"\ud83d\udc50 Add memory to the RAG application","href":"/ai-rag-lab/docs/add-memory/add-memory","docId":"add-memory/add-memory","unlisted":false}],"href":"/ai-rag-lab/docs/category/add-memory-to-the-rag-application"},{"type":"link","label":"\ud83c\udfaf Summary","href":"/ai-rag-lab/docs/summary","docId":"summary","unlisted":false}]},"docs":{"add-memory/add-memory":{"id":"add-memory/add-memory","title":"\ud83d\udc50 Add memory to the RAG application","description":"In many Q&A applications we want to allow the user to have a back-and-forth conversation with the LLM, meaning the application needs some sort of \\"memory\\" of past questions and answers, and some logic for incorporating those into its current thinking. In this section, you will retrieve chat message history from MongoDB and incorporate it in your RAG application.","sidebar":"tutorialSidebar"},"build-rag-app/add-reranking":{"id":"build-rag-app/add-reranking","title":"\ud83e\uddb9 Re-rank retrieved results","description":"Re-rankers are specialized models that are trained to calculate the relevance between query-document pairs. Without re-ranking the order of retrieved results is governed by the embedding model, which isn\'t optimized for relevance and can lead to poor LLM recall in RAG applications.","sidebar":"tutorialSidebar"},"build-rag-app/build-rag-app":{"id":"build-rag-app/build-rag-app","title":"\ud83d\udc50 Build the RAG application","description":"Let\'s create a simple RAG workflow that takes in a user query, retrieves contextually relevant documents from MongoDB Atlas, and passes the query and retrieved context to an LLM to generate an answer to the user question.","sidebar":"tutorialSidebar"},"dev-env/dev-setup":{"id":"dev-env/dev-setup","title":"\ud83d\udc50 Setup dev environment","description":"If you are doing this lab as part of a MongoDB GenAI Developer Day, at this point you should already have the GitHub Codespace ready for this lab, so you can skip the following steps and continue using the Codespace you created previously.","sidebar":"tutorialSidebar"},"dev-env/jupyter-notebooks":{"id":"dev-env/jupyter-notebooks","title":"\ud83d\udcd8 Running Jupyter Notebooks","description":"Jupyter Notebooks is an interactive Python environment.","sidebar":"tutorialSidebar"},"dev-env/setup-pre-reqs":{"id":"dev-env/setup-pre-reqs","title":"\ud83d\udc50 Setup prerequisites","description":"Replace any placeholders and run the cells under Step 1: Setup prerequisites section in the notebook.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction","description":"|Lab goals|Learn how to build a documentation chatbot|","sidebar":"tutorialSidebar"},"mongodb-atlas/setup":{"id":"mongodb-atlas/setup","title":"\ud83d\udc50 MongoDB Setup","description":"If you are doing this lab as part of a MongoDB GenAI Developer Day, at this point you should already have a free cluster, so you can skip this step.","sidebar":"tutorialSidebar"},"perform-semantic-search/concepts":{"id":"perform-semantic-search/concepts","title":"\ud83d\udcd8 Semantic search in MongoDB","description":"In MongoDB, you can semantically search through your data using MongoDB Atlas Vector Search.","sidebar":"tutorialSidebar"},"perform-semantic-search/create-vector-index":{"id":"perform-semantic-search/create-vector-index","title":"\ud83d\udc50 Create a vector search index","description":"To retrieve documents from MongoDB using vector search, you must configure a vector search index on the collection into which you ingested your data. The recommended way to do this is via the MongoDB drivers.","sidebar":"tutorialSidebar"},"perform-semantic-search/pre-filtering":{"id":"perform-semantic-search/pre-filtering","title":"\ud83e\uddb9 Combine pre-filtering with vector search","description":"Pre-filtering is a technique to optimize vector search by only considering documents that match certain criteria during vector search.","sidebar":"tutorialSidebar"},"perform-semantic-search/vector-search":{"id":"perform-semantic-search/vector-search","title":"\ud83d\udc50 Perform semantic search","description":"Now let\'s run some vector search queries against the data present in MongoDB.","sidebar":"tutorialSidebar"},"prepare-the-data/chunk-data":{"id":"prepare-the-data/chunk-data","title":"\ud83d\udc50 Chunk up the data","description":"Since we are working with large documents, we first need to break them up into smaller chunks before embedding and storing them in MongoDB.","sidebar":"tutorialSidebar"},"prepare-the-data/embed-data":{"id":"prepare-the-data/embed-data","title":"\ud83d\udc50 Generate embeddings","description":"To perform vector search on the data, we need to embed it (i.e. generate embedding vectors) before ingesting it into MongoDB.","sidebar":"tutorialSidebar"},"prepare-the-data/ingest-data":{"id":"prepare-the-data/ingest-data","title":"\ud83d\udc50 Ingest data into MongoDB","description":"The final step to build a MongoDB vector store for the chatbot is to ingest the embedded article chunks into MongoDB.","sidebar":"tutorialSidebar"},"prepare-the-data/load-data":{"id":"prepare-the-data/load-data","title":"\ud83d\udc50 Load the dataset","description":"First, let\'s download the dataset for the lab. We\'ll use a subset of MongoDB\'s technical documentation as the source data for the documentation chatbot.","sidebar":"tutorialSidebar"},"rag/components-of-rag":{"id":"rag/components-of-rag","title":"\ud83d\udcd8 Components of a RAG system","description":"RAG systems have two main components: Retrieval and Generation.","sidebar":"tutorialSidebar"},"rag/rag-usecases":{"id":"rag/rag-usecases","title":"\ud83d\udcd8 When to use RAG?","description":"RAG is best suited for the following:","sidebar":"tutorialSidebar"},"rag/what-is-rag":{"id":"rag/what-is-rag","title":"\ud83d\udcd8 What is RAG?","description":"RAG, short for Retrieval Augmented Generation, is a technique to enhance the quality of responses generated by a large language model (LLM), by augmenting its pre-trained knowledge with information retrieved from external sources. This results is more accurate responses from the LLM by grounding them in real, contextually relevant data.","sidebar":"tutorialSidebar"},"summary":{"id":"summary","title":"\ud83c\udfaf Summary","description":"Congratulations! Following this lab, you have successfully:","sidebar":"tutorialSidebar"}}}}')}}]);